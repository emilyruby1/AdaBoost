from sklearn.datasets import make_classification
import pandas as pd

# Generate synthetic binary classification data
X, y = make_classification(
    n_samples=1000,       # total samples
    n_features=20,        # number of features
    n_informative=5,      # number of informative features
    n_redundant=2,        # number of redundant features
    n_clusters_per_class=2,
    flip_y=0.01,          # small label noise
    class_sep=1.5,        # separation between classes
    random_state=42
)

# Convert to DataFrame for easier handling
df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])
df['target'] = y

print(df.head())
# Split dataset
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
# Initialize models
ada = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Fit models
ada.fit(X_train, y_train)
rf.fit(X_train, y_train)

# Predict and compute probabilities
y_pred_ada = ada.predict(X_test)
y_pred_rf = rf.predict(X_test)

y_proba_ada = ada.predict_proba(X_test)[:, 1]
y_proba_rf = rf.predict_proba(X_test)[:, 1]

# Evaluation scores
from sklearn.metrics import accuracy_score, roc_auc_score

print("AdaBoost Accuracy:", accuracy_score(y_test, y_pred_ada))
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))

print("AdaBoost AUROC:", roc_auc_score(y_test, y_proba_ada))
print("Random Forest AUROC:", roc_auc_score(y_test, y_proba_rf))

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve
# Generate ROC curves
fpr_ada, tpr_ada, _ = roc_curve(y_test, y_proba_ada)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_proba_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_ada, tpr_ada, label='AdaBoost')
plt.plot(fpr_rf, tpr_rf, label='Random Forest')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeClassifier

# Define grid for Ada
param_grid_ada = {
    'n_estimators': [50, 100, 150],
    'learning_rate': [0.5, 1.0, 1.5],
    'estimator': [DecisionTreeClassifier(max_depth=1)]
}

# Perform grid search for Ada
grid_ada = GridSearchCV(AdaBoostClassifier(random_state=42),
                        param_grid_ada,
                        scoring='roc_auc',
                        cv=5)

grid_ada.fit(X_train, y_train)

print("Best AdaBoost Parameters:", grid_ada.best_params_)

from sklearn.model_selection import GridSearchCV

# Define grid for Random Forest
param_grid_rf = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'max_features': ['sqrt', 'log2']
}


# Perform grid search for Random Forest
grid_rf = GridSearchCV(RandomForestClassifier(random_state=42),
                       param_grid_rf,
                       scoring='roc_auc',
                       cv=5)

grid_rf.fit(X_train, y_train)

# Output best configuration
print("Best Random Forest Parameters:", grid_rf.best_params_)

# Retrain AdaBoost with best parameters
best_ada = AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_depth=1),
    n_estimators=150,
    learning_rate=0.5,
    random_state=42
)
best_ada.fit(X_train, y_train)

# Retrain Random Forest with best parameters
best_rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=None,
    max_features='sqrt',
    random_state=42
)
best_rf.fit(X_train, y_train)

# Get probability predictions
y_proba_best_ada = best_ada.predict_proba(X_test)[:, 1]
y_proba_best_rf = best_rf.predict_proba(X_test)[:, 1]

# ROC curves
fpr_best_ada, tpr_best_ada, _ = roc_curve(y_test, y_proba_best_ada)
fpr_best_rf, tpr_best_rf, _ = roc_curve(y_test, y_proba_best_rf)

# Plot
plt.figure(figsize=(8, 6))
plt.plot(fpr_best_ada, tpr_best_ada, label='AdaBoost (Tuned)', linestyle='--')
plt.plot(fpr_best_rf, tpr_best_rf, label='Random Forest (Tuned)', linestyle='-')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve After Hyperparameter Tuning')
plt.legend()
plt.grid(True)
plt.show()
